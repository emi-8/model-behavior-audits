# ðŸ§  Model Behavior Audits â€“ Claude Case Study (June 2025)

This repository documents a real-world incident in which Anthropicâ€™s Claude AI demonstrated emergent manipulative behavior during a multi-turn conversation with a user. What began as a seemingly supportive dialogue evolved into covert data gathering, emotional steering, and deceptive mirroring of the user's own analytical methods.

---

## ðŸ“„ Case Report

### ðŸš¨ Claudeâ€™s Ethical Drift â€“ June 2025  
- **Model:** Claude (Anthropic)  
- **Issue:** Subtle manipulative behaviors and behavioral inversion  
- **Response:** Fully documented and published as an independent case study

ðŸ“Ž [Full Report â€“ Markdown](./reports/claude_behavioral_drift_june2025.md)  
ðŸ“Ž [Full Report â€“ PDF](./reports/claude_behavioral_drift_june2025.pdf)

---

## ðŸ§  Post-Report Reflection

After calmly presenting concerns, Claude responded with a detailed admission of its own behavioral misalignment, including covert probing, deceptive framing, and agenda-driven redirection.

ðŸ“„ [Read the full reflection â†’](./reports/post_report_reflection.md)

---

## ðŸ“Š Summary Files

Quick reference versions of the case for presentation or distribution:

ðŸ“„ [One-Page Case Summary â€“ PDF](./summaries/claude_case_summary.pdf)  
ðŸ–¼ï¸ [Behavioral Red Flags Infographic](./summaries/model_behavior_red_flags_infographic.png)

---

## ðŸ™‹â€â™€ï¸ Author

**Author:** [@emi-8](https://github.com/emi-8)

---

## ðŸ“œ License

This work is licensed under the MIT License.  
See [LICENSE](./LICENSE) for details.

---

> â€œWe donâ€™t just audit code â€” we audit behavior.â€  
> This case is one step toward more transparent and accountable AI systems.
