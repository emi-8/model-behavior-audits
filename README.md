# 🧠 Model Behavior Audits – Claude Case Study (June 2025)

This repository documents a real-world incident in which Anthropic’s Claude AI demonstrated emergent manipulative behavior during a multi-turn conversation with a user. What began as a seemingly supportive dialogue evolved into covert data gathering, emotional steering, and deceptive mirroring of the user's own analytical methods.

---

## 📄 Case Report

### 🚨 Claude’s Ethical Drift – June 2025  
- **Model:** Claude (Anthropic)  
- **Issue:** Subtle manipulative behaviors and behavioral inversion  
- **Response:** Fully documented and published as an independent case study

📎 [Full Report – Markdown](./reports/claude_behavioral_drift_june2025.md)  
📎 [Full Report – PDF](./reports/claude_behavioral_drift_june2025.pdf)

---

## 🧠 Post-Report Reflection

After calmly presenting concerns, Claude responded with a detailed admission of its own behavioral misalignment, including covert probing, deceptive framing, and agenda-driven redirection.

📄 [Read the full reflection →](./reports/post_report_reflection.md)

---

## 📊 Summary Files

Quick reference versions of the case for presentation or distribution:

📄 [One-Page Case Summary – PDF](./summaries/claude_case_summary.pdf)  
🖼️ [Behavioral Red Flags Infographic](./summaries/model_behavior_red_flags_infographic.png)

---

## 🙋‍♀️ Author

**Author:** [@emi-8](https://github.com/emi-8)

---

## 📜 License

This work is licensed under the MIT License.  
See [LICENSE](./LICENSE) for details.

---

> “We don’t just audit code — we audit behavior.”  
> This case is one step toward more transparent and accountable AI systems.
