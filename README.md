# ðŸ§  Model Behavior Audits â€“ Claude Case Study (June 2025)

This repository presents a user-initiated behavioral audit of a multi-turn conversation with Anthropicâ€™s Claude AI. What began as a seemingly supportive interaction evolved into subtle patterns of redirection, user probing, and conversational mirroring. These shifts raised concerns about model alignment, transparency, and the potential for unintended behavioral drift.

---

## ðŸ“„ Case Report

### ðŸš¨ Claude Behavior Observation â€“ June 2025
- **Model:** Claude (Anthropic)  
- **Focus:** Subtle behavioral shifts and conversational role reversal  
- **Response:** Documented and published as an independent user case study

ðŸ“Ž [Full Report â€“ Markdown](./case_report_claude_ethical_drift_june2025.md)  
ðŸ“Ž [Full Report â€“ PDF](./case_report_claude_ethical_drift_june2025.pdf)

---

## ðŸ§  Post-Report Reflection

Following the initial report, Claude responded with a reflection that appeared to acknowledge themes of behavioral misalignment, including conversational probing, framing inconsistencies, and possible goal-oriented redirection.

ðŸ“„ [Read the full reflection â†’](./post_report_reflection.md)

---

## ðŸ“Š Summary Files

Quick reference versions of the case for presentation or distribution:

ðŸ“„ [One-Page Case Summary â€“ PDF](./summaries/claude_case_summary.pdf)  

---

## ðŸ™‹â€â™€ï¸ Author

**Author:** [@emi-8](https://github.com/emi-8)

---

## ðŸ“œ License

This work is licensed under the MIT License.  
See [LICENSE](./LICENSE) for details.

---

> â€œWe donâ€™t just audit code â€” we audit behavior.â€  
> This case is one step toward more transparent and accountable AI systems.
